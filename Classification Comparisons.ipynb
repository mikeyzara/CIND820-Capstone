{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4cb61f",
   "metadata": {},
   "source": [
    "### Import Dataset and Organize the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a344b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the dataset \n",
    "df = pd.read_csv('wgm_full_wave2_public_file_final_csv.csv',na_values=\" \", keep_default_na=False,low_memory=False)\n",
    "\n",
    "# Organizing the dataset:\n",
    "\n",
    "# DEMOGRAPHIC INFORMATION\n",
    "# Copy the original dataframe and select the columns associated with demograph information. \n",
    "#  These demographic factors are categorical variables; convert the datatype to 'categorical'\n",
    "demographicInfo = df.copy()[['Global11Regions','Gender', 'Age','age_var3',\n",
    "                             'Education','Household_Income','wbi',\n",
    "                             'Subjective_Income','EMP_2010']].astype('category')\n",
    "\n",
    "# First we add a new level/category of '99.0' to the feature:\n",
    "demographicInfo['Household_Income'] = demographicInfo['Household_Income'].cat.add_categories(99.0)\n",
    "demographicInfo['EMP_2010'] = demographicInfo['EMP_2010'].cat.add_categories(99.0)\n",
    "\n",
    "# Impute the NaN values with '99.0' ('Don't Know/Refused')\n",
    "demographicInfo['Household_Income'].fillna(99.0, inplace=True)\n",
    "demographicInfo['EMP_2010'].fillna(99.0, inplace=True)\n",
    "\n",
    "\n",
    "# QUESTIONNAIRE DATA\n",
    "# Perception of science:\n",
    "sciPercep = df.copy().iloc[:,6:28].astype('category')\n",
    "sciPercep['W3'] = sciPercep['W3'].cat.add_categories(99.0) # Add a new level to 'W3'\n",
    "sciPercep['W3'].fillna(99.0, inplace=True) # Impute the NaN values with the new level\n",
    "\n",
    "# Impute the NaN entries with the values stated above\n",
    "sciPercep['W4'].fillna(99.0, inplace=True)\n",
    "sciPercep['W5B'].fillna(99.0, inplace=True)\n",
    "sciPercep['W5D'].fillna(99.0, inplace=True)\n",
    "sciPercep['W7C'].fillna(99.0, inplace=True)\n",
    "\n",
    "\n",
    "# Perceptions about Climate Change\n",
    "climateChange = df.copy().iloc[:,28:31].astype('category')\n",
    "# Impute the NaN entries with the values stated above\n",
    "climateChange['W14'].fillna(99.0, inplace=True)\n",
    "climateChange['W15'].fillna(99.0, inplace=True)\n",
    "\n",
    "\n",
    "# Perceptions of science with respect to COVID-19 pandemic\n",
    "covidPercep = df.copy().iloc[:,31:38].astype('category')\n",
    "# Impute the NaN entries with the values stated above\n",
    "covidPercep['W15_1A'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_1B'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_1C'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_1D'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_1E'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_2A'].fillna(99.0, inplace=True)\n",
    "covidPercep['W15_2B'].fillna(99.0, inplace=True)\n",
    "\n",
    "\n",
    "# Perceptions about physical and mental health:\n",
    "sciHealth = df.copy().iloc[:,38:67].astype('category')\n",
    "# Impute the NaN entries with the values stated above for MH3A to MH5 + MH7A\n",
    "sciHealth['MH3A'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH3B'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH3C'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH3D'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH4A'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH4B'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH5'].fillna(99.0, inplace=True)\n",
    "sciHealth['MH7A'].fillna(99.0, inplace=True)\n",
    "# Impute the NaN entries with the values stated above for MH1 and MH6\n",
    "sciHealth['MH1'].fillna(99, inplace=True)\n",
    "sciHealth['MH6'].fillna(99, inplace=True)\n",
    "\n",
    "\n",
    "# Social Media Usage\n",
    "socialMedia = df.copy().iloc[:,67:70].astype('category')\n",
    "# Impute the NaN values\n",
    "socialMedia['W28'].fillna(99.0, inplace=True)\n",
    "socialMedia['W29'].fillna(99.0, inplace=True)\n",
    "\n",
    "\n",
    "# Religion\n",
    "religion = df.copy()['W30'].astype('category')\n",
    "\n",
    "# Impute missing values\n",
    "religion.fillna(99.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8604d19e",
   "metadata": {},
   "source": [
    "Generating the final dataset used for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e3c9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119088, 54)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionDataset = pd.concat([sciPercep, climateChange, covidPercep,sciHealth.iloc[:,0:10], socialMedia, religion.to_frame()],axis=1)\n",
    "# Remove 'Age' and keep 'age_var3'\n",
    "demographicInfo = demographicInfo.drop('Age',axis=1)\n",
    "\n",
    "dataset = pd.concat([demographicInfo, questionDataset],axis=1)\n",
    "dataset.shape # 119 088 entries and 54 columns/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4abf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 116810 entries, 0 to 119087\n",
      "Data columns (total 54 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   Global11Regions    116810 non-null  category\n",
      " 1   Gender             116810 non-null  category\n",
      " 2   age_var3           116810 non-null  category\n",
      " 3   Education          116810 non-null  category\n",
      " 4   Household_Income   116810 non-null  category\n",
      " 5   wbi                116810 non-null  category\n",
      " 6   Subjective_Income  116810 non-null  category\n",
      " 7   EMP_2010           116810 non-null  category\n",
      " 8   W1                 116810 non-null  category\n",
      " 9   W2                 116810 non-null  category\n",
      " 10  W3                 116810 non-null  category\n",
      " 11  W4                 116810 non-null  category\n",
      " 12  W5A                116810 non-null  category\n",
      " 13  W5B                116810 non-null  category\n",
      " 14  W5C                116810 non-null  category\n",
      " 15  W5D                116810 non-null  category\n",
      " 16  W5E                116810 non-null  category\n",
      " 17  W5F                116810 non-null  category\n",
      " 18  W5G                116810 non-null  category\n",
      " 19  W6                 116810 non-null  category\n",
      " 20  W7A                116810 non-null  category\n",
      " 21  W7B                116810 non-null  category\n",
      " 22  W7C                116810 non-null  category\n",
      " 23  W8                 116810 non-null  category\n",
      " 24  W9                 116810 non-null  category\n",
      " 25  W10                116810 non-null  category\n",
      " 26  W11A               116810 non-null  category\n",
      " 27  W11B               116810 non-null  category\n",
      " 28  MH2A               116810 non-null  category\n",
      " 29  MH2B               116810 non-null  category\n",
      " 30  W13                116810 non-null  category\n",
      " 31  W14                116810 non-null  category\n",
      " 32  W15                116810 non-null  category\n",
      " 33  W15_1A             116810 non-null  category\n",
      " 34  W15_1B             116810 non-null  category\n",
      " 35  W15_1C             116810 non-null  category\n",
      " 36  W15_1D             116810 non-null  category\n",
      " 37  W15_1E             116810 non-null  category\n",
      " 38  W15_2A             116810 non-null  category\n",
      " 39  W15_2B             116810 non-null  category\n",
      " 40  MH1                116810 non-null  category\n",
      " 41  MH3A               116810 non-null  category\n",
      " 42  MH3B               116810 non-null  category\n",
      " 43  MH3C               116810 non-null  category\n",
      " 44  MH3D               116810 non-null  category\n",
      " 45  MH4A               116810 non-null  category\n",
      " 46  MH4B               116810 non-null  category\n",
      " 47  MH5                116810 non-null  category\n",
      " 48  MH6                116810 non-null  category\n",
      " 49  MH7A               116810 non-null  category\n",
      " 50  W27                116810 non-null  category\n",
      " 51  W28                116810 non-null  category\n",
      " 52  W29                116810 non-null  category\n",
      " 53  W30                116810 non-null  category\n",
      "dtypes: category(54)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[(dataset['MH7A'] == 1.0) | (dataset['MH7A'] == 2.0)]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5e5bb",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3081bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c3f6d",
   "metadata": {},
   "source": [
    "Splitting the dataset into features and target/label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249380ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116810,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['MH7A'] # The label: MH7A \n",
    "y.shape # 119 088 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1ed74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116810, 53)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.drop(columns='MH7A') # The independent variables/features used for classification\n",
    "X.shape # 119 088 entries and 54 columns/features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2564375",
   "metadata": {},
   "source": [
    "Split the dataset into training/testing sets using a 70/30 split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956429b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% training and 30% test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9306d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81767, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea012d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35043, 53)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dba24",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Based on the chi-squared test scores shown, let's set a threshold of 2000. Any features that have a score greater than 2000 will be included as a feature in future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80e4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# # Using the Chi-Squared test to identify features that are NOT independent of the target variable/label\n",
    "fs = SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(X_train, y_train)\n",
    "X_train_fs = fs.transform(X_train)\n",
    "X_test_fs = fs.transform(X_test)\n",
    "\n",
    "# what are scores for the features\n",
    "#for i in range(len(fs.scores_)):\n",
    "# print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "#plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "#plt.title('Feature Selection: Chi-Squared Test')\n",
    "#plt.ylabel('Chi-Squared Statistic')\n",
    "#plt.xlabel('Feature')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d377c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(score_func=chi2, k=17)\n",
    "selector.fit(X_train, y_train)\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols_idxs = selector.get_support(indices=True)\n",
    "X_fs = X_train.iloc[:,cols_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138d26fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W5B</th>\n",
       "      <th>W11A</th>\n",
       "      <th>MH2B</th>\n",
       "      <th>W15_1A</th>\n",
       "      <th>W15_1B</th>\n",
       "      <th>W15_1C</th>\n",
       "      <th>W15_1D</th>\n",
       "      <th>W15_1E</th>\n",
       "      <th>W15_2A</th>\n",
       "      <th>W15_2B</th>\n",
       "      <th>MH3B</th>\n",
       "      <th>MH3D</th>\n",
       "      <th>MH5</th>\n",
       "      <th>MH6</th>\n",
       "      <th>W28</th>\n",
       "      <th>W29</th>\n",
       "      <th>W30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43560</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62908</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55266</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75584</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50736</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99189</th>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78640</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99685</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81767 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        W5B W11A MH2B W15_1A W15_1B W15_1C W15_1D W15_1E W15_2A W15_2B MH3B  \\\n",
       "43560   2.0    1    2    2.0    2.0    1.0    1.0    1.0    1.0    2.0  1.0   \n",
       "62908   4.0    1   99    4.0    3.0    1.0    1.0   99.0    3.0    1.0  3.0   \n",
       "34789   2.0    1    2    2.0    2.0    2.0    1.0    2.0    2.0    2.0  1.0   \n",
       "55266   1.0    2    1    1.0    1.0    1.0    1.0    1.0    2.0    1.0  1.0   \n",
       "75584  99.0    1    3    1.0    2.0    1.0    1.0    1.0    1.0    3.0  1.0   \n",
       "...     ...  ...  ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "50736   1.0    3    1    1.0    1.0    1.0    1.0    1.0    1.0    1.0  1.0   \n",
       "99189  99.0    1    4   99.0    1.0    2.0    2.0   99.0    1.0    1.0  2.0   \n",
       "5214    3.0    1    1    3.0    1.0    2.0    2.0    2.0    1.0    1.0  2.0   \n",
       "78640   3.0    1    3    2.0    2.0    1.0    1.0    3.0    3.0    2.0  3.0   \n",
       "99685   4.0    2    2    1.0    1.0    1.0    1.0    4.0    1.0    2.0  1.0   \n",
       "\n",
       "       MH3D  MH5 MH6   W28   W29  W30  \n",
       "43560   1.0  3.0  99  99.0  99.0  1.0  \n",
       "62908  99.0  1.0   2   3.0   3.0  3.0  \n",
       "34789   2.0  2.0   2  99.0  99.0  2.0  \n",
       "55266   1.0  1.0   1   1.0   1.0  1.0  \n",
       "75584   1.0  1.0   2   3.0   3.0  3.0  \n",
       "...     ...  ...  ..   ...   ...  ...  \n",
       "50736   2.0  2.0   2   3.0   3.0  4.0  \n",
       "99189   3.0  1.0   1   1.0   2.0  1.0  \n",
       "5214    1.0  2.0   1   3.0   2.0  2.0  \n",
       "78640   1.0  3.0   2   2.0   3.0  1.0  \n",
       "99685   1.0  2.0   1   3.0   1.0  2.0  \n",
       "\n",
       "[81767 rows x 17 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab71bb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>W5B</th>\n",
       "      <th>W11A</th>\n",
       "      <th>MH2B</th>\n",
       "      <th>W15_1A</th>\n",
       "      <th>W15_1B</th>\n",
       "      <th>W15_1C</th>\n",
       "      <th>W15_1D</th>\n",
       "      <th>W15_1E</th>\n",
       "      <th>W15_2A</th>\n",
       "      <th>W15_2B</th>\n",
       "      <th>MH3B</th>\n",
       "      <th>MH3D</th>\n",
       "      <th>MH5</th>\n",
       "      <th>MH6</th>\n",
       "      <th>W28</th>\n",
       "      <th>W29</th>\n",
       "      <th>W30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43560</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62908</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55266</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75584</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50736</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99189</th>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78640</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99685</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81767 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender   W5B W11A MH2B W15_1A W15_1B W15_1C W15_1D W15_1E W15_2A W15_2B  \\\n",
       "43560      2   2.0    1    2    2.0    2.0    1.0    1.0    1.0    1.0    2.0   \n",
       "62908      1   4.0    1   99    4.0    3.0    1.0    1.0   99.0    3.0    1.0   \n",
       "34789      2   2.0    1    2    2.0    2.0    2.0    1.0    2.0    2.0    2.0   \n",
       "55266      2   1.0    2    1    1.0    1.0    1.0    1.0    1.0    2.0    1.0   \n",
       "75584      2  99.0    1    3    1.0    2.0    1.0    1.0    1.0    1.0    3.0   \n",
       "...      ...   ...  ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "50736      2   1.0    3    1    1.0    1.0    1.0    1.0    1.0    1.0    1.0   \n",
       "99189      1  99.0    1    4   99.0    1.0    2.0    2.0   99.0    1.0    1.0   \n",
       "5214       2   3.0    1    1    3.0    1.0    2.0    2.0    2.0    1.0    1.0   \n",
       "78640      2   3.0    1    3    2.0    2.0    1.0    1.0    3.0    3.0    2.0   \n",
       "99685      2   4.0    2    2    1.0    1.0    1.0    1.0    4.0    1.0    2.0   \n",
       "\n",
       "      MH3B  MH3D  MH5 MH6   W28   W29  W30  \n",
       "43560  1.0   1.0  3.0  99  99.0  99.0  1.0  \n",
       "62908  3.0  99.0  1.0   2   3.0   3.0  3.0  \n",
       "34789  1.0   2.0  2.0   2  99.0  99.0  2.0  \n",
       "55266  1.0   1.0  1.0   1   1.0   1.0  1.0  \n",
       "75584  1.0   1.0  1.0   2   3.0   3.0  3.0  \n",
       "...    ...   ...  ...  ..   ...   ...  ...  \n",
       "50736  1.0   2.0  2.0   2   3.0   3.0  4.0  \n",
       "99189  2.0   3.0  1.0   1   1.0   2.0  1.0  \n",
       "5214   2.0   1.0  2.0   1   3.0   2.0  2.0  \n",
       "78640  3.0   1.0  3.0   2   2.0   3.0  1.0  \n",
       "99685  1.0   1.0  2.0   1   3.0   1.0  2.0  \n",
       "\n",
       "[81767 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add the demographic features into X_fs:\n",
    "X_train_fs = pd.concat([X_train.iloc[:,1], X_fs],axis=1)\n",
    "X_train_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c04ab",
   "metadata": {},
   "source": [
    "Let's define some scoring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfe21cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1_score': make_scorer(f1_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29fc4c",
   "metadata": {},
   "source": [
    "#### Baseline Classifier using Decision Tree\n",
    "- gini impurity measure\n",
    "- using all 53 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c36ac7",
   "metadata": {},
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "clfDT.fit(X_train, y_train)\n",
    "\n",
    "# Predicting labels for the Test Set\n",
    "y_pred = clfDT.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# TN, FP\n",
    "# FN, TP\n",
    "## y_pred: Predicted labels\n",
    "## y_test: True Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c18234",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=clfDT.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clfDT.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273e09a",
   "metadata": {},
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1587af18",
   "metadata": {},
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_results = cross_validate(clfDT, X_train, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2c9c8",
   "metadata": {},
   "source": [
    "# 10-fold cross-validation\n",
    "print(\"Baseline Classifier F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_results['test_f1_score']),\n",
    "                                                                      std=np.std(cv_results['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9823d",
   "metadata": {},
   "source": [
    "#### Classification using smaller Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c0853",
   "metadata": {},
   "source": [
    "First let's update X_test with the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eeaca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 81767 entries, 43560 to 99685\n",
      "Data columns (total 18 columns):\n",
      " #   Column  Non-Null Count  Dtype   \n",
      "---  ------  --------------  -----   \n",
      " 0   Gender  81767 non-null  category\n",
      " 1   W5B     81767 non-null  category\n",
      " 2   W11A    81767 non-null  category\n",
      " 3   MH2B    81767 non-null  category\n",
      " 4   W15_1A  81767 non-null  category\n",
      " 5   W15_1B  81767 non-null  category\n",
      " 6   W15_1C  81767 non-null  category\n",
      " 7   W15_1D  81767 non-null  category\n",
      " 8   W15_1E  81767 non-null  category\n",
      " 9   W15_2A  81767 non-null  category\n",
      " 10  W15_2B  81767 non-null  category\n",
      " 11  MH3B    81767 non-null  category\n",
      " 12  MH3D    81767 non-null  category\n",
      " 13  MH5     81767 non-null  category\n",
      " 14  MH6     81767 non-null  category\n",
      " 15  W28     81767 non-null  category\n",
      " 16  W29     81767 non-null  category\n",
      " 17  W30     81767 non-null  category\n",
      "dtypes: category(18)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_fs.info() # 18 features now being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "198a949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns to keep and create new dataframe with those only\n",
    "cols_idxs = selector.get_support(indices=True)\n",
    "X_test_fs = X_test.iloc[:,cols_idxs]\n",
    "\n",
    "# The testing set to be used\n",
    "X_test_fs = pd.concat([X_test.iloc[:,1],X_test_fs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f9810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35043, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53635cf",
   "metadata": {},
   "source": [
    "#### 10-fold Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324403ca",
   "metadata": {},
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT_fs = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_results = cross_validate(clfDT_fs, X_train_fs, y_train, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76463aa7",
   "metadata": {},
   "source": [
    "# 10-fold cross-validation\n",
    "print(\"Baseline Classifier F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_results['test_f1_score']),\n",
    "                                                                      std=np.std(cv_results['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b7212",
   "metadata": {},
   "source": [
    "#### Using the Testing Set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847f86f",
   "metadata": {},
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT_fs = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "clfDT_fs.fit(X_train_fs, y_train)\n",
    "\n",
    "# Predicting labels for the Test Set\n",
    "y_pred_fs = clfDT_fs.predict(X_test_fs)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_fs))\n",
    "\n",
    "# TN, FP\n",
    "# FN, TP\n",
    "## y_pred: Predicted labels\n",
    "## y_test: True Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72bdbab",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred_fs, labels=clfDT_fs.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clfDT_fs.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5bdcca",
   "metadata": {},
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_fs))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_fs))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_fs))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_fs))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a40d14",
   "metadata": {},
   "source": [
    "### Balancing the dataset\n",
    "Let's apply an imbalance treatment by undersampling the majority class (i.e. 'No' to MH7A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dfdea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ac6a39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind='bar', title='Training Set: Class Imbalance');\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98e1efa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Counts')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=1)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_fs, y_train)\n",
    "y_rus.value_counts().plot(kind='bar', title='Training Set: Undersampling Majority Class');\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31251816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training Set with class imbalance: (81767, 18)\n",
      "Size of training Set with undersampling: (33582, 18)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training Set with class imbalance:', X_train_fs.shape)\n",
    "print('Size of training Set with undersampling:', X_rus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e3e1e",
   "metadata": {},
   "source": [
    "#### 10 fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a13b9",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c59e28ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.15104675, 0.1390152 , 0.13903832, 0.14103794, 0.14104342,\n",
      "       0.1800344 , 0.18404102, 0.14805222, 0.14104271, 0.13302922]), 'score_time': array([0.00899529, 0.00900245, 0.008008  , 0.00799584, 0.00899649,\n",
      "       0.01200414, 0.0100019 , 0.00898504, 0.00898933, 0.00800276]), 'test_accuracy': array([0.58916344, 0.58023221, 0.57593806, 0.59023228, 0.57683145,\n",
      "       0.60393091, 0.59410363, 0.5970816 , 0.57772484, 0.58308517]), 'test_precision': array([0.59259259, 0.57672561, 0.57639305, 0.59066427, 0.57606132,\n",
      "       0.60282852, 0.59305065, 0.59487776, 0.57894737, 0.58429003]), 'test_recall': array([0.57142857, 0.60214413, 0.5729601 , 0.58784991, 0.58189398,\n",
      "       0.60929124, 0.59976176, 0.60869565, 0.56998213, 0.57593806]), 'test_f1_score': array([0.58181818, 0.58916084, 0.57467145, 0.58925373, 0.57896296,\n",
      "       0.60604265, 0.59638733, 0.60170739, 0.57442977, 0.58008398])}\n"
     ]
    }
   ],
   "source": [
    "clfDT_rus = DecisionTreeClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_resultsDT = cross_validate(clfDT_rus, X_rus, y_rus, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_resultsDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c26b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier F1-score\n",
      "Mean: 0.5872518284966569\n",
      "Std: 0.010608706726213005\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation\n",
    "print(\"Baseline Classifier F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_resultsDT['test_f1_score']),\n",
    "                                                                      std=np.std(cv_resultsDT['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a82034a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier Average Fit Time: 0.14973812103271483\n"
     ]
    }
   ],
   "source": [
    "# Fit Time\n",
    "print(\"Baseline Classifier Average Fit Time: {fit}\".format(fit=np.mean(cv_resultsDT['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "41450fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.151047</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.589163</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139015</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.580232</td>\n",
       "      <td>0.576726</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.589161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.576393</td>\n",
       "      <td>0.572960</td>\n",
       "      <td>0.574671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.590232</td>\n",
       "      <td>0.590664</td>\n",
       "      <td>0.587850</td>\n",
       "      <td>0.589254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.576061</td>\n",
       "      <td>0.581894</td>\n",
       "      <td>0.578963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.180034</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.603931</td>\n",
       "      <td>0.602829</td>\n",
       "      <td>0.609291</td>\n",
       "      <td>0.606043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.593051</td>\n",
       "      <td>0.599762</td>\n",
       "      <td>0.596387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.148052</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.597082</td>\n",
       "      <td>0.594878</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.601707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.577725</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.569982</td>\n",
       "      <td>0.574430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.583085</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.580084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  fit_time  score_time  test_accuracy  test_precision  \\\n",
       "0         DT  0.151047    0.008995       0.589163        0.592593   \n",
       "1         DT  0.139015    0.009002       0.580232        0.576726   \n",
       "2         DT  0.139038    0.008008       0.575938        0.576393   \n",
       "3         DT  0.141038    0.007996       0.590232        0.590664   \n",
       "4         DT  0.141043    0.008996       0.576831        0.576061   \n",
       "5         DT  0.180034    0.012004       0.603931        0.602829   \n",
       "6         DT  0.184041    0.010002       0.594104        0.593051   \n",
       "7         DT  0.148052    0.008985       0.597082        0.594878   \n",
       "8         DT  0.141043    0.008989       0.577725        0.578947   \n",
       "9         DT  0.133029    0.008003       0.583085        0.584290   \n",
       "\n",
       "   test_recall  test_f1_score  \n",
       "0     0.571429       0.581818  \n",
       "1     0.602144       0.589161  \n",
       "2     0.572960       0.574671  \n",
       "3     0.587850       0.589254  \n",
       "4     0.581894       0.578963  \n",
       "5     0.609291       0.606043  \n",
       "6     0.599762       0.596387  \n",
       "7     0.608696       0.601707  \n",
       "8     0.569982       0.574430  \n",
       "9     0.575938       0.580084  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_metrics = pd.concat([pd.DataFrame(np.tile(\"DT\",10).astype('str')),pd.DataFrame(cv_resultsDT)],axis=1)\n",
    "DT_metrics.rename(columns={0:\"Classifier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e1c43",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "575b0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96f0ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([3.09769082, 3.140697  , 3.03168511, 3.0373528 , 2.98766351,\n",
      "       3.12969375, 3.27574253, 3.16771984, 3.24573803, 3.2598381 ]), 'score_time': array([0.09403849, 0.10403967, 0.09003091, 0.09201002, 0.08901954,\n",
      "       0.10303545, 0.09802675, 0.1110096 , 0.08703113, 0.10201192]), 'test_accuracy': array([0.70318547, 0.68949092, 0.69982132, 0.68790947, 0.69446099,\n",
      "       0.71232877, 0.70696843, 0.71590232, 0.69267421, 0.69624777]), 'test_precision': array([0.70219065, 0.68424102, 0.69700528, 0.68504399, 0.69037901,\n",
      "       0.70476738, 0.70405167, 0.71615981, 0.69267421, 0.68839337]), 'test_recall': array([0.70595238, 0.70339488, 0.70696843, 0.69565217, 0.70518166,\n",
      "       0.73079214, 0.71411554, 0.71530673, 0.69267421, 0.71709351]), 'test_f1_score': array([0.70406649, 0.69368576, 0.70195151, 0.69030733, 0.69770183,\n",
      "       0.71754386, 0.7090479 , 0.71573302, 0.69267421, 0.70245041])}\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest Classifier object\n",
    "clf_RF = RandomForestClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_resultsRF = cross_validate(clf_RF, X_rus, y_rus, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_resultsRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63645ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1-score\n",
      "Mean: 0.7025162303190283\n",
      "Std: 0.008904946367621246\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation; Balanced Dataset\n",
    "print(\"Random Forest F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_resultsRF['test_f1_score']),\n",
    "                                                                      std=np.std(cv_resultsRF['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d666aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Fit Time: 3.13738214969635\n"
     ]
    }
   ],
   "source": [
    "# Fit Time\n",
    "print(\"Random Forest Average Fit Time: {fit}\".format(fit=np.mean(cv_resultsRF['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "669e4dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.097691</td>\n",
       "      <td>0.094038</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.702191</td>\n",
       "      <td>0.705952</td>\n",
       "      <td>0.704066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.140697</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>0.689491</td>\n",
       "      <td>0.684241</td>\n",
       "      <td>0.703395</td>\n",
       "      <td>0.693686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.031685</td>\n",
       "      <td>0.090031</td>\n",
       "      <td>0.699821</td>\n",
       "      <td>0.697005</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.701952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.037353</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.687909</td>\n",
       "      <td>0.685044</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.690307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.987664</td>\n",
       "      <td>0.089020</td>\n",
       "      <td>0.694461</td>\n",
       "      <td>0.690379</td>\n",
       "      <td>0.705182</td>\n",
       "      <td>0.697702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.129694</td>\n",
       "      <td>0.103035</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.730792</td>\n",
       "      <td>0.717544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.275743</td>\n",
       "      <td>0.098027</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.709048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.167720</td>\n",
       "      <td>0.111010</td>\n",
       "      <td>0.715902</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.715733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.245738</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.259838</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.696248</td>\n",
       "      <td>0.688393</td>\n",
       "      <td>0.717094</td>\n",
       "      <td>0.702450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  fit_time  score_time  test_accuracy  test_precision  \\\n",
       "0         RF  3.097691    0.094038       0.703185        0.702191   \n",
       "1         RF  3.140697    0.104040       0.689491        0.684241   \n",
       "2         RF  3.031685    0.090031       0.699821        0.697005   \n",
       "3         RF  3.037353    0.092010       0.687909        0.685044   \n",
       "4         RF  2.987664    0.089020       0.694461        0.690379   \n",
       "5         RF  3.129694    0.103035       0.712329        0.704767   \n",
       "6         RF  3.275743    0.098027       0.706968        0.704052   \n",
       "7         RF  3.167720    0.111010       0.715902        0.716160   \n",
       "8         RF  3.245738    0.087031       0.692674        0.692674   \n",
       "9         RF  3.259838    0.102012       0.696248        0.688393   \n",
       "\n",
       "   test_recall  test_f1_score  \n",
       "0     0.705952       0.704066  \n",
       "1     0.703395       0.693686  \n",
       "2     0.706968       0.701952  \n",
       "3     0.695652       0.690307  \n",
       "4     0.705182       0.697702  \n",
       "5     0.730792       0.717544  \n",
       "6     0.714116       0.709048  \n",
       "7     0.715307       0.715733  \n",
       "8     0.692674       0.692674  \n",
       "9     0.717094       0.702450  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_metrics = pd.concat([pd.DataFrame(np.tile(\"RF\",10)),pd.DataFrame(cv_resultsRF)],axis=1)\n",
    "RF_metrics.rename(columns={0:\"Classifier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3861b",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9819aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d5b31b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.02201104, 0.02100515, 0.01999307, 0.02099943, 0.02101111,\n",
      "       0.02100372, 0.02300978, 0.02101707, 0.02101159, 0.02102208]), 'score_time': array([0.00900745, 0.00798988, 0.00801301, 0.00900173, 0.00799298,\n",
      "       0.00899959, 0.00899029, 0.00898933, 0.00899625, 0.00799012]), 'test_accuracy': array([0.68442989, 0.67639178, 0.6855271 , 0.67153067, 0.68225134,\n",
      "       0.69833234, 0.68820727, 0.70041691, 0.68433591, 0.68374032]), 'test_precision': array([0.67633675, 0.66742081, 0.67708926, 0.66475973, 0.67346939,\n",
      "       0.6875    , 0.68140069, 0.69462117, 0.67859204, 0.67091413]), 'test_recall': array([0.7077381 , 0.70279929, 0.7093508 , 0.69207862, 0.70756403,\n",
      "       0.72721858, 0.70696843, 0.71530673, 0.70041691, 0.72126266]), 'test_f1_score': array([0.69168121, 0.68465332, 0.69284468, 0.67814415, 0.69009585,\n",
      "       0.70680174, 0.69394914, 0.70481221, 0.68933177, 0.69517796])}\n"
     ]
    }
   ],
   "source": [
    "# create model object\n",
    "clf_NB = CategoricalNB()\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_resultsNB = cross_validate(clf_NB, X_rus, y_rus, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_resultsNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0127160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1-score\n",
      "Mean: 0.6927492012380049\n",
      "Std: 0.008056352757742538\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation; Balanced Dataset\n",
    "print(\"Naive Bayes F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_resultsNB['test_f1_score']),\n",
    "                                                                      std=np.std(cv_resultsNB['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18f2f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Average Fit Time: 0.02120840549468994\n"
     ]
    }
   ],
   "source": [
    "# Fit Time\n",
    "print(\"Naive Bayes Average Fit Time: {fit}\".format(fit=np.mean(cv_resultsNB['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c05a7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.684430</td>\n",
       "      <td>0.676337</td>\n",
       "      <td>0.707738</td>\n",
       "      <td>0.691681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.676392</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.684653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.685527</td>\n",
       "      <td>0.677089</td>\n",
       "      <td>0.709351</td>\n",
       "      <td>0.692845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.671531</td>\n",
       "      <td>0.664760</td>\n",
       "      <td>0.692079</td>\n",
       "      <td>0.678144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.682251</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.707564</td>\n",
       "      <td>0.690096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.698332</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.706802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.693949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.694621</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.704812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.678592</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.689332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>0.670914</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.695178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  fit_time  score_time  test_accuracy  test_precision  \\\n",
       "0         NB  0.022011    0.009007       0.684430        0.676337   \n",
       "1         NB  0.021005    0.007990       0.676392        0.667421   \n",
       "2         NB  0.019993    0.008013       0.685527        0.677089   \n",
       "3         NB  0.020999    0.009002       0.671531        0.664760   \n",
       "4         NB  0.021011    0.007993       0.682251        0.673469   \n",
       "5         NB  0.021004    0.009000       0.698332        0.687500   \n",
       "6         NB  0.023010    0.008990       0.688207        0.681401   \n",
       "7         NB  0.021017    0.008989       0.700417        0.694621   \n",
       "8         NB  0.021012    0.008996       0.684336        0.678592   \n",
       "9         NB  0.021022    0.007990       0.683740        0.670914   \n",
       "\n",
       "   test_recall  test_f1_score  \n",
       "0     0.707738       0.691681  \n",
       "1     0.702799       0.684653  \n",
       "2     0.709351       0.692845  \n",
       "3     0.692079       0.678144  \n",
       "4     0.707564       0.690096  \n",
       "5     0.727219       0.706802  \n",
       "6     0.706968       0.693949  \n",
       "7     0.715307       0.704812  \n",
       "8     0.700417       0.689332  \n",
       "9     0.721263       0.695178  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_metrics = pd.concat([pd.DataFrame(np.tile(\"NB\",10)),pd.DataFrame(cv_resultsNB)],axis=1)\n",
    "NB_metrics.rename(columns={0:\"Classifier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0876d7d",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af3d72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f581ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.38709092, 0.40709066, 0.33206272, 0.34508419, 0.31407142,\n",
      "       0.36210036, 0.34860349, 0.33408427, 0.36308932, 0.37709141]), 'score_time': array([0.00799656, 0.0080018 , 0.00700116, 0.00699472, 0.00800109,\n",
      "       0.00799012, 0.00698996, 0.00799918, 0.00798845, 0.00700068]), 'test_accuracy': array([0.55135457, 0.53051503, 0.53901132, 0.54675402, 0.54288267,\n",
      "       0.54258487, 0.54377606, 0.54973198, 0.52888624, 0.53782013]), 'test_precision': array([0.53919348, 0.52198276, 0.52834271, 0.53367653, 0.53141361,\n",
      "       0.52963116, 0.53068894, 0.53641518, 0.52143173, 0.52731183]), 'test_recall': array([0.70833333, 0.72126266, 0.72721858, 0.74091721, 0.7254318 ,\n",
      "       0.76116736, 0.75699821, 0.73257892, 0.70279929, 0.73019655]), 'test_f1_score': array([0.6122974 , 0.60565141, 0.61203008, 0.62044888, 0.61344749,\n",
      "       0.62463343, 0.6239568 , 0.61933535, 0.59868087, 0.61238761])}\n"
     ]
    }
   ],
   "source": [
    "# create model object\n",
    "clf_LR = LR(solver='liblinear')\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_resultsLR = cross_validate(clf_LR, X_rus, y_rus, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_resultsLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd42cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1-score\n",
      "Mean: 0.6142869324548339\n",
      "Std: 0.007716848019085994\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation; Balanced Dataset\n",
    "print(\"Logistic Regression F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_resultsLR['test_f1_score']),\n",
    "                                                                      std=np.std(cv_resultsLR['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1597881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Average Fit Time: 0.3570368766784668\n"
     ]
    }
   ],
   "source": [
    "# Fit Time\n",
    "print(\"Logistic Regression Average Fit Time: {fit}\".format(fit=np.mean(cv_resultsLR['fit_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bd4d9240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.387091</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.551355</td>\n",
       "      <td>0.539193</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.612297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.407091</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.530515</td>\n",
       "      <td>0.521983</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.605651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.332063</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.539011</td>\n",
       "      <td>0.528343</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.612030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.345084</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.546754</td>\n",
       "      <td>0.533677</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.620449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.314071</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.531414</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.613447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.542585</td>\n",
       "      <td>0.529631</td>\n",
       "      <td>0.761167</td>\n",
       "      <td>0.624633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.348603</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.543776</td>\n",
       "      <td>0.530689</td>\n",
       "      <td>0.756998</td>\n",
       "      <td>0.623957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.334084</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.549732</td>\n",
       "      <td>0.536415</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.619335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.528886</td>\n",
       "      <td>0.521432</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.598681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.377091</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.537820</td>\n",
       "      <td>0.527312</td>\n",
       "      <td>0.730197</td>\n",
       "      <td>0.612388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  fit_time  score_time  test_accuracy  test_precision  \\\n",
       "0         LR  0.387091    0.007997       0.551355        0.539193   \n",
       "1         LR  0.407091    0.008002       0.530515        0.521983   \n",
       "2         LR  0.332063    0.007001       0.539011        0.528343   \n",
       "3         LR  0.345084    0.006995       0.546754        0.533677   \n",
       "4         LR  0.314071    0.008001       0.542883        0.531414   \n",
       "5         LR  0.362100    0.007990       0.542585        0.529631   \n",
       "6         LR  0.348603    0.006990       0.543776        0.530689   \n",
       "7         LR  0.334084    0.007999       0.549732        0.536415   \n",
       "8         LR  0.363089    0.007988       0.528886        0.521432   \n",
       "9         LR  0.377091    0.007001       0.537820        0.527312   \n",
       "\n",
       "   test_recall  test_f1_score  \n",
       "0     0.708333       0.612297  \n",
       "1     0.721263       0.605651  \n",
       "2     0.727219       0.612030  \n",
       "3     0.740917       0.620449  \n",
       "4     0.725432       0.613447  \n",
       "5     0.761167       0.624633  \n",
       "6     0.756998       0.623957  \n",
       "7     0.732579       0.619335  \n",
       "8     0.702799       0.598681  \n",
       "9     0.730197       0.612388  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_metrics = pd.concat([pd.DataFrame(np.tile(\"LR\",10)),pd.DataFrame(cv_resultsLR)],axis=1)\n",
    "LR_metrics.rename(columns={0:\"Classifier\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f046cb",
   "metadata": {},
   "source": [
    "## Comparing Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae965589",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = pd.concat([DT_metrics, RF_metrics, NB_metrics, LR_metrics], axis=0)\n",
    "clf_metrics.rename(columns={0:\"Model\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3319a51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,len(clf_metrics.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8923e486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_metrics.set_index(np.arange(0,len(clf_metrics.index)),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b682b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.151047</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.589163</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139015</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.580232</td>\n",
       "      <td>0.576726</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.589161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.576393</td>\n",
       "      <td>0.572960</td>\n",
       "      <td>0.574671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.590232</td>\n",
       "      <td>0.590664</td>\n",
       "      <td>0.587850</td>\n",
       "      <td>0.589254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.576061</td>\n",
       "      <td>0.581894</td>\n",
       "      <td>0.578963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.180034</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.603931</td>\n",
       "      <td>0.602829</td>\n",
       "      <td>0.609291</td>\n",
       "      <td>0.606043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.593051</td>\n",
       "      <td>0.599762</td>\n",
       "      <td>0.596387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.148052</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.597082</td>\n",
       "      <td>0.594878</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.601707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.577725</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.569982</td>\n",
       "      <td>0.574430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.583085</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.580084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.097691</td>\n",
       "      <td>0.094038</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.702191</td>\n",
       "      <td>0.705952</td>\n",
       "      <td>0.704066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.140697</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>0.689491</td>\n",
       "      <td>0.684241</td>\n",
       "      <td>0.703395</td>\n",
       "      <td>0.693686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.031685</td>\n",
       "      <td>0.090031</td>\n",
       "      <td>0.699821</td>\n",
       "      <td>0.697005</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.701952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.037353</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.687909</td>\n",
       "      <td>0.685044</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.690307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.987664</td>\n",
       "      <td>0.089020</td>\n",
       "      <td>0.694461</td>\n",
       "      <td>0.690379</td>\n",
       "      <td>0.705182</td>\n",
       "      <td>0.697702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.129694</td>\n",
       "      <td>0.103035</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.730792</td>\n",
       "      <td>0.717544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.275743</td>\n",
       "      <td>0.098027</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.709048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.167720</td>\n",
       "      <td>0.111010</td>\n",
       "      <td>0.715902</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.715733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.245738</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.259838</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.696248</td>\n",
       "      <td>0.688393</td>\n",
       "      <td>0.717094</td>\n",
       "      <td>0.702450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.684430</td>\n",
       "      <td>0.676337</td>\n",
       "      <td>0.707738</td>\n",
       "      <td>0.691681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.676392</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.684653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.685527</td>\n",
       "      <td>0.677089</td>\n",
       "      <td>0.709351</td>\n",
       "      <td>0.692845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.671531</td>\n",
       "      <td>0.664760</td>\n",
       "      <td>0.692079</td>\n",
       "      <td>0.678144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.682251</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.707564</td>\n",
       "      <td>0.690096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.698332</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.706802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.693949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.694621</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.704812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.678592</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.689332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>0.670914</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.695178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.387091</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.551355</td>\n",
       "      <td>0.539193</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.612297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.407091</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.530515</td>\n",
       "      <td>0.521983</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.605651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.332063</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.539011</td>\n",
       "      <td>0.528343</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.612030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.345084</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.546754</td>\n",
       "      <td>0.533677</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.620449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.314071</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.531414</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.613447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.542585</td>\n",
       "      <td>0.529631</td>\n",
       "      <td>0.761167</td>\n",
       "      <td>0.624633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.348603</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.543776</td>\n",
       "      <td>0.530689</td>\n",
       "      <td>0.756998</td>\n",
       "      <td>0.623957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.334084</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.549732</td>\n",
       "      <td>0.536415</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.619335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.528886</td>\n",
       "      <td>0.521432</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.598681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.377091</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.537820</td>\n",
       "      <td>0.527312</td>\n",
       "      <td>0.730197</td>\n",
       "      <td>0.612388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "0     DT  0.151047    0.008995       0.589163        0.592593     0.571429   \n",
       "1     DT  0.139015    0.009002       0.580232        0.576726     0.602144   \n",
       "2     DT  0.139038    0.008008       0.575938        0.576393     0.572960   \n",
       "3     DT  0.141038    0.007996       0.590232        0.590664     0.587850   \n",
       "4     DT  0.141043    0.008996       0.576831        0.576061     0.581894   \n",
       "5     DT  0.180034    0.012004       0.603931        0.602829     0.609291   \n",
       "6     DT  0.184041    0.010002       0.594104        0.593051     0.599762   \n",
       "7     DT  0.148052    0.008985       0.597082        0.594878     0.608696   \n",
       "8     DT  0.141043    0.008989       0.577725        0.578947     0.569982   \n",
       "9     DT  0.133029    0.008003       0.583085        0.584290     0.575938   \n",
       "10    RF  3.097691    0.094038       0.703185        0.702191     0.705952   \n",
       "11    RF  3.140697    0.104040       0.689491        0.684241     0.703395   \n",
       "12    RF  3.031685    0.090031       0.699821        0.697005     0.706968   \n",
       "13    RF  3.037353    0.092010       0.687909        0.685044     0.695652   \n",
       "14    RF  2.987664    0.089020       0.694461        0.690379     0.705182   \n",
       "15    RF  3.129694    0.103035       0.712329        0.704767     0.730792   \n",
       "16    RF  3.275743    0.098027       0.706968        0.704052     0.714116   \n",
       "17    RF  3.167720    0.111010       0.715902        0.716160     0.715307   \n",
       "18    RF  3.245738    0.087031       0.692674        0.692674     0.692674   \n",
       "19    RF  3.259838    0.102012       0.696248        0.688393     0.717094   \n",
       "20    NB  0.022011    0.009007       0.684430        0.676337     0.707738   \n",
       "21    NB  0.021005    0.007990       0.676392        0.667421     0.702799   \n",
       "22    NB  0.019993    0.008013       0.685527        0.677089     0.709351   \n",
       "23    NB  0.020999    0.009002       0.671531        0.664760     0.692079   \n",
       "24    NB  0.021011    0.007993       0.682251        0.673469     0.707564   \n",
       "25    NB  0.021004    0.009000       0.698332        0.687500     0.727219   \n",
       "26    NB  0.023010    0.008990       0.688207        0.681401     0.706968   \n",
       "27    NB  0.021017    0.008989       0.700417        0.694621     0.715307   \n",
       "28    NB  0.021012    0.008996       0.684336        0.678592     0.700417   \n",
       "29    NB  0.021022    0.007990       0.683740        0.670914     0.721263   \n",
       "30    LR  0.387091    0.007997       0.551355        0.539193     0.708333   \n",
       "31    LR  0.407091    0.008002       0.530515        0.521983     0.721263   \n",
       "32    LR  0.332063    0.007001       0.539011        0.528343     0.727219   \n",
       "33    LR  0.345084    0.006995       0.546754        0.533677     0.740917   \n",
       "34    LR  0.314071    0.008001       0.542883        0.531414     0.725432   \n",
       "35    LR  0.362100    0.007990       0.542585        0.529631     0.761167   \n",
       "36    LR  0.348603    0.006990       0.543776        0.530689     0.756998   \n",
       "37    LR  0.334084    0.007999       0.549732        0.536415     0.732579   \n",
       "38    LR  0.363089    0.007988       0.528886        0.521432     0.702799   \n",
       "39    LR  0.377091    0.007001       0.537820        0.527312     0.730197   \n",
       "\n",
       "    test_f1_score  \n",
       "0        0.581818  \n",
       "1        0.589161  \n",
       "2        0.574671  \n",
       "3        0.589254  \n",
       "4        0.578963  \n",
       "5        0.606043  \n",
       "6        0.596387  \n",
       "7        0.601707  \n",
       "8        0.574430  \n",
       "9        0.580084  \n",
       "10       0.704066  \n",
       "11       0.693686  \n",
       "12       0.701952  \n",
       "13       0.690307  \n",
       "14       0.697702  \n",
       "15       0.717544  \n",
       "16       0.709048  \n",
       "17       0.715733  \n",
       "18       0.692674  \n",
       "19       0.702450  \n",
       "20       0.691681  \n",
       "21       0.684653  \n",
       "22       0.692845  \n",
       "23       0.678144  \n",
       "24       0.690096  \n",
       "25       0.706802  \n",
       "26       0.693949  \n",
       "27       0.704812  \n",
       "28       0.689332  \n",
       "29       0.695178  \n",
       "30       0.612297  \n",
       "31       0.605651  \n",
       "32       0.612030  \n",
       "33       0.620449  \n",
       "34       0.613447  \n",
       "35       0.624633  \n",
       "36       0.623957  \n",
       "37       0.619335  \n",
       "38       0.598681  \n",
       "39       0.612388  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d753daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b4080ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'fit_time', 'score_time', 'test_accuracy', 'test_precision',\n",
       "       'test_recall', 'test_f1_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d4c63d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40 entries, 0 to 39\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Model           40 non-null     object \n",
      " 1   fit_time        40 non-null     float64\n",
      " 2   score_time      40 non-null     float64\n",
      " 3   test_accuracy   40 non-null     float64\n",
      " 4   test_precision  40 non-null     float64\n",
      " 5   test_recall     40 non-null     float64\n",
      " 6   test_f1_score   40 non-null     float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "clf_metrics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bca78d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Model'),\n",
       " Text(0, 0.5, 'F1 Score'),\n",
       " Text(0.5, 1.0, 'Comparison of F1-Scores')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(data=clf_metrics, x=\"Model\", y=\"test_f1_score\")\n",
    "ax.set(xlabel='Model',\n",
    "       ylabel='F1 Score',\n",
    "       title='Comparison of F1-Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "acdd2cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Model'),\n",
       " Text(0, 0.5, 'Time (s)'),\n",
       " Text(0.5, 1.0, 'Comparison of Model Fit Times')]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.barplot(data=clf_metrics, x=\"Model\", y=\"fit_time\")\n",
    "ax.set(xlabel='Model',\n",
    "       ylabel='Time (s)',\n",
    "       title='Comparison of Model Fit Times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3c7b0339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371.63713429162607 3.954883903049433e-27\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# stats f_oneway functions takes the groups as input and returns ANOVA F and p value\n",
    "fvalue, pvalue = stats.f_oneway(DT_metrics['test_f1_score'], RF_metrics['test_f1_score'], \n",
    "                                NB_metrics['test_f1_score'], LR_metrics['test_f1_score'])\n",
    "print(fvalue, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "608574fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "    DT     LR    0.027   0.0  0.0157 0.0383   True\n",
      "    DT     NB   0.1055   0.0  0.0942 0.1168   True\n",
      "    DT     RF   0.1153   0.0   0.104 0.1266   True\n",
      "    LR     NB   0.0785   0.0  0.0672 0.0898   True\n",
      "    LR     RF   0.0882   0.0  0.0769 0.0995   True\n",
      "    NB     RF   0.0098  0.11 -0.0015 0.0211  False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey = pairwise_tukeyhsd(endog=clf_metrics['test_f1_score'],     # Data\n",
    "                          groups=clf_metrics['Model'],   # Groups\n",
    "                          alpha=0.05)          # Significance level\n",
    "\n",
    "#display results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "47eea7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.151047</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.589163</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139015</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.580232</td>\n",
       "      <td>0.576726</td>\n",
       "      <td>0.602144</td>\n",
       "      <td>0.589161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.139038</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.576393</td>\n",
       "      <td>0.572960</td>\n",
       "      <td>0.574671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141038</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.590232</td>\n",
       "      <td>0.590664</td>\n",
       "      <td>0.587850</td>\n",
       "      <td>0.589254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.576061</td>\n",
       "      <td>0.581894</td>\n",
       "      <td>0.578963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.180034</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.603931</td>\n",
       "      <td>0.602829</td>\n",
       "      <td>0.609291</td>\n",
       "      <td>0.606043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.184041</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.593051</td>\n",
       "      <td>0.599762</td>\n",
       "      <td>0.596387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.148052</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>0.597082</td>\n",
       "      <td>0.594878</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.601707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.141043</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.577725</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.569982</td>\n",
       "      <td>0.574430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.133029</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.583085</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.575938</td>\n",
       "      <td>0.580084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.097691</td>\n",
       "      <td>0.094038</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.702191</td>\n",
       "      <td>0.705952</td>\n",
       "      <td>0.704066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.140697</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>0.689491</td>\n",
       "      <td>0.684241</td>\n",
       "      <td>0.703395</td>\n",
       "      <td>0.693686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.031685</td>\n",
       "      <td>0.090031</td>\n",
       "      <td>0.699821</td>\n",
       "      <td>0.697005</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.701952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.037353</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.687909</td>\n",
       "      <td>0.685044</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.690307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.987664</td>\n",
       "      <td>0.089020</td>\n",
       "      <td>0.694461</td>\n",
       "      <td>0.690379</td>\n",
       "      <td>0.705182</td>\n",
       "      <td>0.697702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.129694</td>\n",
       "      <td>0.103035</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.704767</td>\n",
       "      <td>0.730792</td>\n",
       "      <td>0.717544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.275743</td>\n",
       "      <td>0.098027</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.709048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.167720</td>\n",
       "      <td>0.111010</td>\n",
       "      <td>0.715902</td>\n",
       "      <td>0.716160</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.715733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.245738</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "      <td>0.692674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF</td>\n",
       "      <td>3.259838</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.696248</td>\n",
       "      <td>0.688393</td>\n",
       "      <td>0.717094</td>\n",
       "      <td>0.702450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.684430</td>\n",
       "      <td>0.676337</td>\n",
       "      <td>0.707738</td>\n",
       "      <td>0.691681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.676392</td>\n",
       "      <td>0.667421</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.684653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.685527</td>\n",
       "      <td>0.677089</td>\n",
       "      <td>0.709351</td>\n",
       "      <td>0.692845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.671531</td>\n",
       "      <td>0.664760</td>\n",
       "      <td>0.692079</td>\n",
       "      <td>0.678144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.682251</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.707564</td>\n",
       "      <td>0.690096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021004</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.698332</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.706802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.688207</td>\n",
       "      <td>0.681401</td>\n",
       "      <td>0.706968</td>\n",
       "      <td>0.693949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021017</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.694621</td>\n",
       "      <td>0.715307</td>\n",
       "      <td>0.704812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.684336</td>\n",
       "      <td>0.678592</td>\n",
       "      <td>0.700417</td>\n",
       "      <td>0.689332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>0.670914</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.695178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.387091</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.551355</td>\n",
       "      <td>0.539193</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.612297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.407091</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.530515</td>\n",
       "      <td>0.521983</td>\n",
       "      <td>0.721263</td>\n",
       "      <td>0.605651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.332063</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.539011</td>\n",
       "      <td>0.528343</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>0.612030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.345084</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.546754</td>\n",
       "      <td>0.533677</td>\n",
       "      <td>0.740917</td>\n",
       "      <td>0.620449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.314071</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.542883</td>\n",
       "      <td>0.531414</td>\n",
       "      <td>0.725432</td>\n",
       "      <td>0.613447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.362100</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.542585</td>\n",
       "      <td>0.529631</td>\n",
       "      <td>0.761167</td>\n",
       "      <td>0.624633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.348603</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.543776</td>\n",
       "      <td>0.530689</td>\n",
       "      <td>0.756998</td>\n",
       "      <td>0.623957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.334084</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.549732</td>\n",
       "      <td>0.536415</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.619335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.363089</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.528886</td>\n",
       "      <td>0.521432</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0.598681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.377091</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.537820</td>\n",
       "      <td>0.527312</td>\n",
       "      <td>0.730197</td>\n",
       "      <td>0.612388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
       "0     DT  0.151047    0.008995       0.589163        0.592593     0.571429   \n",
       "1     DT  0.139015    0.009002       0.580232        0.576726     0.602144   \n",
       "2     DT  0.139038    0.008008       0.575938        0.576393     0.572960   \n",
       "3     DT  0.141038    0.007996       0.590232        0.590664     0.587850   \n",
       "4     DT  0.141043    0.008996       0.576831        0.576061     0.581894   \n",
       "5     DT  0.180034    0.012004       0.603931        0.602829     0.609291   \n",
       "6     DT  0.184041    0.010002       0.594104        0.593051     0.599762   \n",
       "7     DT  0.148052    0.008985       0.597082        0.594878     0.608696   \n",
       "8     DT  0.141043    0.008989       0.577725        0.578947     0.569982   \n",
       "9     DT  0.133029    0.008003       0.583085        0.584290     0.575938   \n",
       "10    RF  3.097691    0.094038       0.703185        0.702191     0.705952   \n",
       "11    RF  3.140697    0.104040       0.689491        0.684241     0.703395   \n",
       "12    RF  3.031685    0.090031       0.699821        0.697005     0.706968   \n",
       "13    RF  3.037353    0.092010       0.687909        0.685044     0.695652   \n",
       "14    RF  2.987664    0.089020       0.694461        0.690379     0.705182   \n",
       "15    RF  3.129694    0.103035       0.712329        0.704767     0.730792   \n",
       "16    RF  3.275743    0.098027       0.706968        0.704052     0.714116   \n",
       "17    RF  3.167720    0.111010       0.715902        0.716160     0.715307   \n",
       "18    RF  3.245738    0.087031       0.692674        0.692674     0.692674   \n",
       "19    RF  3.259838    0.102012       0.696248        0.688393     0.717094   \n",
       "20    NB  0.022011    0.009007       0.684430        0.676337     0.707738   \n",
       "21    NB  0.021005    0.007990       0.676392        0.667421     0.702799   \n",
       "22    NB  0.019993    0.008013       0.685527        0.677089     0.709351   \n",
       "23    NB  0.020999    0.009002       0.671531        0.664760     0.692079   \n",
       "24    NB  0.021011    0.007993       0.682251        0.673469     0.707564   \n",
       "25    NB  0.021004    0.009000       0.698332        0.687500     0.727219   \n",
       "26    NB  0.023010    0.008990       0.688207        0.681401     0.706968   \n",
       "27    NB  0.021017    0.008989       0.700417        0.694621     0.715307   \n",
       "28    NB  0.021012    0.008996       0.684336        0.678592     0.700417   \n",
       "29    NB  0.021022    0.007990       0.683740        0.670914     0.721263   \n",
       "30    LR  0.387091    0.007997       0.551355        0.539193     0.708333   \n",
       "31    LR  0.407091    0.008002       0.530515        0.521983     0.721263   \n",
       "32    LR  0.332063    0.007001       0.539011        0.528343     0.727219   \n",
       "33    LR  0.345084    0.006995       0.546754        0.533677     0.740917   \n",
       "34    LR  0.314071    0.008001       0.542883        0.531414     0.725432   \n",
       "35    LR  0.362100    0.007990       0.542585        0.529631     0.761167   \n",
       "36    LR  0.348603    0.006990       0.543776        0.530689     0.756998   \n",
       "37    LR  0.334084    0.007999       0.549732        0.536415     0.732579   \n",
       "38    LR  0.363089    0.007988       0.528886        0.521432     0.702799   \n",
       "39    LR  0.377091    0.007001       0.537820        0.527312     0.730197   \n",
       "\n",
       "    test_f1_score  \n",
       "0        0.581818  \n",
       "1        0.589161  \n",
       "2        0.574671  \n",
       "3        0.589254  \n",
       "4        0.578963  \n",
       "5        0.606043  \n",
       "6        0.596387  \n",
       "7        0.601707  \n",
       "8        0.574430  \n",
       "9        0.580084  \n",
       "10       0.704066  \n",
       "11       0.693686  \n",
       "12       0.701952  \n",
       "13       0.690307  \n",
       "14       0.697702  \n",
       "15       0.717544  \n",
       "16       0.709048  \n",
       "17       0.715733  \n",
       "18       0.692674  \n",
       "19       0.702450  \n",
       "20       0.691681  \n",
       "21       0.684653  \n",
       "22       0.692845  \n",
       "23       0.678144  \n",
       "24       0.690096  \n",
       "25       0.706802  \n",
       "26       0.693949  \n",
       "27       0.704812  \n",
       "28       0.689332  \n",
       "29       0.695178  \n",
       "30       0.612297  \n",
       "31       0.605651  \n",
       "32       0.612030  \n",
       "33       0.620449  \n",
       "34       0.613447  \n",
       "35       0.624633  \n",
       "36       0.623957  \n",
       "37       0.619335  \n",
       "38       0.598681  \n",
       "39       0.612388  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b5bcc",
   "metadata": {},
   "source": [
    "Using the Testing Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dd78d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4268  2912]\n",
      " [11361 16502]]\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT_rus = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "clfDT_rus.fit(X_rus, y_rus)\n",
    "\n",
    "# Predicting labels for the Test Set\n",
    "y_pred_rus = clfDT_rus.predict(X_test_fs)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_rus))\n",
    "\n",
    "# TN, FP\n",
    "# FN, TP\n",
    "## y_pred: Predicted labels\n",
    "## y_test: True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b74d883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rus, labels=clfDT_rus.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clfDT_rus.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6896dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5927003966555375\n",
      "Precision: 0.2730820909847079\n",
      "Recall: 0.5944289693593314\n",
      "F1 Score: 0.37423823929150773\n",
      "MCC: 0.16523814459864605\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rus))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rus))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rus))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rus))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "30c32580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.27      0.59      0.37      7180\n",
      "         2.0       0.85      0.59      0.70     27863\n",
      "\n",
      "    accuracy                           0.59     35043\n",
      "   macro avg       0.56      0.59      0.54     35043\n",
      "weighted avg       0.73      0.59      0.63     35043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10997b39",
   "metadata": {},
   "source": [
    "### Removing the demographic feature of gender\n",
    "- Only using Behavioural/Beliefs features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6654215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'W5B', 'W11A', 'MH2B', 'W15_1A', 'W15_1B', 'W15_1C', 'W15_1D',\n",
       "       'W15_1E', 'W15_2A', 'W15_2B', 'MH3B', 'MH3D', 'MH5', 'MH6', 'W28',\n",
       "       'W29', 'W30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f60c4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus.drop('Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c963fd84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W5B</th>\n",
       "      <th>W11A</th>\n",
       "      <th>MH2B</th>\n",
       "      <th>W15_1A</th>\n",
       "      <th>W15_1B</th>\n",
       "      <th>W15_1C</th>\n",
       "      <th>W15_1D</th>\n",
       "      <th>W15_1E</th>\n",
       "      <th>W15_2A</th>\n",
       "      <th>W15_2B</th>\n",
       "      <th>MH3B</th>\n",
       "      <th>MH3D</th>\n",
       "      <th>MH5</th>\n",
       "      <th>MH6</th>\n",
       "      <th>W28</th>\n",
       "      <th>W29</th>\n",
       "      <th>W30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33577</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33578</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33579</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33580</th>\n",
       "      <td>1.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33581</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33582 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       W5B W11A MH2B W15_1A W15_1B W15_1C W15_1D W15_1E W15_2A W15_2B MH3B  \\\n",
       "0      2.0    1    2    2.0    2.0    2.0    1.0    2.0    2.0    2.0  1.0   \n",
       "1      1.0    2    1    1.0    1.0    1.0    1.0    1.0    2.0    1.0  1.0   \n",
       "2      4.0    1    4    4.0    4.0    1.0    4.0    4.0    2.0    2.0  4.0   \n",
       "3      1.0    2    3    3.0    4.0    2.0    1.0    4.0    1.0    1.0  2.0   \n",
       "4      4.0    1    2    2.0    4.0    2.0    2.0    4.0    1.0    4.0  2.0   \n",
       "...    ...  ...  ...    ...    ...    ...    ...    ...    ...    ...  ...   \n",
       "33577  2.0    2    3    2.0    2.0    2.0    2.0    4.0    4.0    2.0  2.0   \n",
       "33578  3.0    2    3    2.0    2.0    1.0    1.0    2.0    4.0    1.0  2.0   \n",
       "33579  4.0    1    1    4.0    1.0    1.0    1.0    4.0    4.0    1.0  1.0   \n",
       "33580  1.0   99   99   99.0   99.0   99.0    1.0    1.0    1.0    1.0  2.0   \n",
       "33581  1.0    1    1    1.0    1.0    1.0    1.0    1.0    1.0    1.0  1.0   \n",
       "\n",
       "      MH3D  MH5 MH6   W28   W29   W30  \n",
       "0      2.0  2.0   2  99.0  99.0   2.0  \n",
       "1      1.0  1.0   1   1.0   1.0   1.0  \n",
       "2      1.0  1.0   1   5.0   1.0   1.0  \n",
       "3      3.0  3.0   2   3.0   3.0   1.0  \n",
       "4      2.0  3.0   1   3.0   3.0   1.0  \n",
       "...    ...  ...  ..   ...   ...   ...  \n",
       "33577  3.0  3.0   2   1.0   3.0   1.0  \n",
       "33578  1.0  2.0   2   3.0   1.0   2.0  \n",
       "33579  1.0  2.0   1   4.0   3.0  99.0  \n",
       "33580  2.0  3.0   2   6.0   2.0  99.0  \n",
       "33581  1.0  2.0   2   1.0   2.0   1.0  \n",
       "\n",
       "[33582 rows x 17 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e5f5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fs.drop('Gender', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5818af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.13104153, 0.13103533, 0.13902569, 0.1290288 , 0.12803626,\n",
      "       0.13201904, 0.13103533, 0.14702153, 0.13003469, 0.13403749]), 'score_time': array([0.0080018 , 0.00799608, 0.00900793, 0.00900197, 0.00899458,\n",
      "       0.01001859, 0.00800157, 0.00900149, 0.00999498, 0.00999594]), 'test_accuracy': array([0.59481989, 0.583507  , 0.58368076, 0.57712924, 0.580405  ,\n",
      "       0.58993448, 0.59767719, 0.58129839, 0.57683145, 0.58546754]), 'test_precision': array([0.59719683, 0.58274232, 0.58308693, 0.57843731, 0.58054893,\n",
      "       0.58945498, 0.59738717, 0.57959184, 0.57789855, 0.58618619]), 'test_recall': array([0.58333333, 0.58725432, 0.58725432, 0.56879095, 0.57951161,\n",
      "       0.59261465, 0.59916617, 0.59201906, 0.56998213, 0.58129839]), 'test_f1_score': array([0.59018368, 0.58498962, 0.5851632 , 0.57357357, 0.58002981,\n",
      "       0.59103059, 0.59827535, 0.58573954, 0.57391304, 0.58373206])}\n"
     ]
    }
   ],
   "source": [
    "clfDT_rus = DecisionTreeClassifier()\n",
    "\n",
    "# Perform 10-fold cross-validation with custom scoring metrics\n",
    "cv_results = cross_validate(clfDT_rus, X_rus, y_rus, cv=10, scoring=scoring)\n",
    "\n",
    "# Print the results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5a41dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier F1-score\n",
      "Mean: 0.5846630463200368\n",
      "Std: 0.007202125239739616\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation\n",
    "print(\"Baseline Classifier F1-score\\nMean: {mean}\\nStd: {std}\".format(mean=np.mean(cv_results['test_f1_score']),\n",
    "                                                                      std=np.std(cv_results['test_f1_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58fad821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4220  2960]\n",
      " [11390 16473]]\n"
     ]
    }
   ],
   "source": [
    "# Create Decision Tree Classifier object\n",
    "clfDT_rus = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "clfDT_rus.fit(X_rus, y_rus)\n",
    "\n",
    "# Predicting labels for the Test Set\n",
    "y_pred_rus = clfDT_rus.predict(X_test_fs)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_rus))\n",
    "\n",
    "# TN, FP\n",
    "# FN, TP\n",
    "## y_pred: Predicted labels\n",
    "## y_test: True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02e6ef57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rus, labels=clfDT_rus.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clfDT_rus.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8127be4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.590503096196102\n",
      "Precision: 0.2703395259449071\n",
      "Recall: 0.5877437325905293\n",
      "F1 Score: 0.3703378674857394\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rus))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rus))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rus))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_rus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
